{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PGExplainer on BA-Shapes dataset for 2-layer GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dig.xgraph.dataset import SynGraphDataset\n",
    "from dig.xgraph.models import *\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Data, InMemoryDataset, download_url, extract_zip\n",
    "import os.path as osp\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def index_to_mask(index, size):\n",
    "    mask = torch.zeros(size, dtype=torch.bool, device=index.device)\n",
    "    mask[index] = 1\n",
    "    return mask\n",
    "\n",
    "def split_dataset(dataset):\n",
    "    indices = []\n",
    "    num_classes = 4\n",
    "    train_percent = 0.7\n",
    "    for i in range(num_classes):\n",
    "        index = (dataset.data.y == i).nonzero().view(-1)\n",
    "        index = index[torch.randperm(index.size(0))]\n",
    "        indices.append(index)\n",
    "\n",
    "    train_index = torch.cat([i[:int(len(i) * train_percent)] for i in indices], dim=0)\n",
    "\n",
    "    rest_index = torch.cat([i[int(len(i) * train_percent):] for i in indices], dim=0)\n",
    "    rest_index = rest_index[torch.randperm(rest_index.size(0))]\n",
    "\n",
    "    dataset.data.train_mask = index_to_mask(train_index, size=dataset.data.num_nodes)\n",
    "    dataset.data.val_mask = index_to_mask(rest_index[:len(rest_index) // 2], size=dataset.data.num_nodes)\n",
    "    dataset.data.test_mask = index_to_mask(rest_index[len(rest_index) // 2:], size=dataset.data.num_nodes)\n",
    "\n",
    "    dataset.data, dataset.slices = dataset.collate([dataset.data])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "dataset = SynGraphDataset('./datasets', 'BA_shapes')\n",
    "dataset.data.x = dataset.data.x.to(torch.float32)\n",
    "dataset.data.x = dataset.data.x[:, :1]\n",
    "# dataset.data.y = dataset.data.y[:, 2]\n",
    "dim_node = dataset.num_node_features\n",
    "dim_edge = dataset.num_edge_features\n",
    "# num_targets = dataset.num_classes\n",
    "num_classes = dataset.num_classes\n",
    "\n",
    "splitted_dataset = split_dataset(dataset)\n",
    "splitted_dataset.data.mask = splitted_dataset.data.test_mask\n",
    "splitted_dataset.slices['mask'] = splitted_dataset.slices['train_mask']\n",
    "dataloader = DataLoader(splitted_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load model and checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_checkpoints(root='./'):\n",
    "    if osp.exists(osp.join(root, 'checkpoints')):\n",
    "        return\n",
    "    url = ('https://github.com/divelab/DIG_storage/raw/main/xgraph/checkpoints.zip')\n",
    "    path = download_url(url, root)\n",
    "    extract_zip(path, root)\n",
    "    os.unlink(path)\n",
    "\n",
    "model = GCN_2l_mask(model_level='node', dim_node=dim_node, dim_hidden=300, num_classes=num_classes)\n",
    "model.to(device)\n",
    "check_checkpoints()\n",
    "ckpt_path = osp.join('checkpoints', 'ba_shapes', 'GCN_2l', '0', 'GCN_2l_best.ckpt')\n",
    "model.load_state_dict(torch.load(ckpt_path)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 560/560 [00:00<00:00, 4565.02it/s]\n",
      "560it [00:22, 25.25it/s]\n",
      "560it [00:21, 26.15it/s]\n",
      "560it [00:22, 25.39it/s]\n",
      "560it [00:21, 25.54it/s]\n",
      "560it [00:21, 25.73it/s]\n",
      "560it [00:20, 27.44it/s]\n",
      "560it [00:18, 30.76it/s]\n",
      "560it [00:20, 26.70it/s]\n",
      "560it [00:20, 27.80it/s]\n",
      "560it [00:20, 27.66it/s]\n",
      "560it [00:20, 27.44it/s]\n",
      "560it [00:20, 27.23it/s]\n",
      "560it [00:18, 29.77it/s]\n",
      "560it [00:16, 32.99it/s]\n",
      "560it [00:16, 33.25it/s]\n",
      "560it [00:16, 32.99it/s]\n",
      "560it [00:16, 33.20it/s]\n",
      "560it [00:17, 32.93it/s]\n",
      "560it [00:16, 32.95it/s]\n",
      "560it [00:16, 33.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 8.890169806565558\n",
      "Epoch: 1 | Loss: 8.76961053844009\n",
      "Epoch: 2 | Loss: 8.224634133492197\n",
      "Epoch: 3 | Loss: 7.542380775511265\n",
      "Epoch: 4 | Loss: 6.490872437400477\n",
      "Epoch: 5 | Loss: 5.467061121229615\n",
      "Epoch: 6 | Loss: 4.766756317578256\n",
      "Epoch: 7 | Loss: 4.586263108652617\n",
      "Epoch: 8 | Loss: 4.519045442635459\n",
      "Epoch: 9 | Loss: 4.593296556866595\n",
      "Epoch: 10 | Loss: 4.698037133286042\n",
      "Epoch: 11 | Loss: 4.773418597211795\n",
      "Epoch: 12 | Loss: 4.826412474523697\n",
      "Epoch: 13 | Loss: 4.872106616039361\n",
      "Epoch: 14 | Loss: 4.889234165474773\n",
      "Epoch: 15 | Loss: 4.900321124919823\n",
      "Epoch: 16 | Loss: 4.911629555959787\n",
      "Epoch: 17 | Loss: 4.89921153246292\n",
      "Epoch: 18 | Loss: 4.894524541869759\n",
      "Epoch: 19 | Loss: 4.874472048346486\n",
      "training time is 387.58s\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dig.xgraph.method import PGExplainer\n",
    "explainer = PGExplainer(model, in_channels=900, device=device, explain_graph=False)\n",
    "\n",
    "explainer.train_explanation_network(splitted_dataset)\n",
    "torch.save(explainer.state_dict(), 'tmp.pt')\n",
    "state_dict = torch.load('tmp.pt')\n",
    "explainer.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dig.xgraph.method.pgexplainer import PlotUtils\n",
    "plotutils = PlotUtils(dataset_name='ba_shapes')\n",
    "\n",
    "node_indices = torch.where(dataset[0].test_mask * dataset[0].y != 0)[0].tolist()\n",
    "from dig.xgraph.method.pgexplainer import PlotUtils\n",
    "plotutils = PlotUtils(dataset_name='ba_shapes')\n",
    "data = dataset[0]\n",
    "node_idx = node_indices[6]\n",
    "with torch.no_grad():\n",
    "    walks, masks, related_preds = \\\n",
    "        explainer(data.x, data.edge_index, node_idx=node_idx, y=data.y, top_k=5)\n",
    "\n",
    "\n",
    "explainer.visualization(data, edge_mask=masks[0], top_k=5, plot_utils=plotutils, node_idx=node_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " ### Metric results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explain graph 0 node 10\n",
      "explain graph 0 node 15\n",
      "explain graph 0 node 22\n",
      "explain graph 0 node 25\n",
      "explain graph 0 node 26\n",
      "explain graph 0 node 43\n",
      "explain graph 0 node 64\n",
      "explain graph 0 node 71\n",
      "explain graph 0 node 75\n",
      "explain graph 0 node 77\n",
      "explain graph 0 node 87\n",
      "explain graph 0 node 96\n",
      "explain graph 0 node 126\n",
      "explain graph 0 node 149\n",
      "explain graph 0 node 151\n",
      "explain graph 0 node 155\n",
      "explain graph 0 node 166\n",
      "explain graph 0 node 190\n",
      "explain graph 0 node 196\n",
      "explain graph 0 node 210\n",
      "explain graph 0 node 243\n",
      "explain graph 0 node 253\n",
      "explain graph 0 node 263\n",
      "explain graph 0 node 269\n",
      "explain graph 0 node 279\n",
      "explain graph 0 node 282\n",
      "explain graph 0 node 288\n",
      "explain graph 0 node 297\n",
      "explain graph 0 node 302\n",
      "explain graph 0 node 313\n",
      "explain graph 0 node 321\n",
      "explain graph 0 node 332\n",
      "explain graph 0 node 336\n",
      "explain graph 0 node 348\n",
      "explain graph 0 node 356\n",
      "explain graph 0 node 367\n",
      "explain graph 0 node 369\n",
      "explain graph 0 node 381\n",
      "explain graph 0 node 387\n",
      "explain graph 0 node 418\n",
      "explain graph 0 node 454\n",
      "explain graph 0 node 461\n",
      "explain graph 0 node 466\n",
      "explain graph 0 node 469\n",
      "explain graph 0 node 471\n",
      "explain graph 0 node 497\n",
      "explain graph 0 node 508\n",
      "explain graph 0 node 514\n",
      "explain graph 0 node 515\n",
      "explain graph 0 node 532\n",
      "explain graph 0 node 542\n",
      "explain graph 0 node 548\n",
      "explain graph 0 node 561\n",
      "explain graph 0 node 564\n",
      "explain graph 0 node 569\n",
      "explain graph 0 node 586\n",
      "explain graph 0 node 588\n",
      "explain graph 0 node 595\n",
      "explain graph 0 node 616\n",
      "explain graph 0 node 621\n",
      "explain graph 0 node 648\n",
      "explain graph 0 node 655\n",
      "explain graph 0 node 663\n",
      "explain graph 0 node 665\n",
      "explain graph 0 node 673\n",
      "explain graph 0 node 690\n",
      "explain graph 0 node 691\n",
      "explain graph 0 node 694\n",
      "explain graph 0 node 696\n",
      "explain graph 0 node 699\n",
      "Fidelity: 0.4858\n",
      "Sparsity: 0.7377\n"
     ]
    }
   ],
   "source": [
    "# --- Create data collector and explanation processor ---\n",
    "from dig.xgraph.evaluation import XCollector\n",
    "x_collector = XCollector()\n",
    "\n",
    "### Run explainer on the given model and dataset\n",
    "index = -1\n",
    "for i, data in enumerate(dataloader):\n",
    "    for j, node_idx in enumerate(torch.where(data.test_mask)[0].tolist()):\n",
    "        index += 1\n",
    "        print(f'explain graph {i} node {node_idx}')\n",
    "        data.to(device)\n",
    "\n",
    "        if torch.isnan(data.y[0].squeeze()):\n",
    "            continue\n",
    "\n",
    "        with torch.no_grad():\n",
    "            walks, masks, related_preds = \\\n",
    "                explainer(data.x, data.edge_index, node_idx=node_idx, y=data.y, top_k=5)\n",
    "            masks = [mask.detach() for mask in masks]\n",
    "        x_collector.collect_data(masks, related_preds)\n",
    "\n",
    "        # if you only have the edge masks without related_pred, please feed sparsity controlled mask to\n",
    "        # obtain the result: x_processor(data, masks, x_collector)\n",
    "        if index >= 99:\n",
    "            break\n",
    "\n",
    "    if index >= 99:\n",
    "        break\n",
    "\n",
    "print(f'Fidelity: {x_collector.fidelity:.4f}\\n'\n",
    "      f'Sparsity: {x_collector.sparsity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}